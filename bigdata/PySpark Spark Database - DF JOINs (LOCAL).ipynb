{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configure before creating SparkSession\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "config = SparkConf()\n",
    "conf = \\\n",
    "(\n",
    "    config\n",
    "    .setMaster(\"spark://192.168.11.77:7077\").setAppName(\"SparkDB\")\n",
    "    .set(\"spark.executor.memory\", \"2g\")\n",
    "    .set(\"spark.executor.cores\", 4)\n",
    "    .set(\"spark.cores.max\", 4)\n",
    "    .set(\"spark.driver.memory\", \"2g\")\n",
    "    .set(\"spark.local.dir\", \"C:/spark-temp\")     # TEMPORARY HARDCODING: Spark's temp\n",
    "    .set(\"spark.sql.warehouse.dir\", \"C:/spark\")  # TEMPORARY HARDCODING: Spark's warehouse\n",
    ")\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------+\n",
      "|product_id|product_name|brand_id|\n",
      "+----------+------------+--------+\n",
      "|         1|      iPhone|     100|\n",
      "|         2|      Galaxy|     200|\n",
      "|         3|       RedMi|     300|\n",
      "|         4|       Pixel|     400|\n",
      "+----------+------------+--------+\n",
      "\n",
      "+--------+----------+\n",
      "|brand_id|brand_name|\n",
      "+--------+----------+\n",
      "|     100|     Apple|\n",
      "|     200|   Samsung|\n",
      "|     400|    Google|\n",
      "|     500|      Sony|\n",
      "+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = (\n",
    "    # (product_id, product_name, brand_id)  \n",
    "    (1, 'iPhone', 100),\n",
    "    (2, 'Galaxy', 200),\n",
    "    (3, 'RedMi', 300),  # orphan record, no matching brand\n",
    "    (4, 'Pixel', 400),\n",
    ")\n",
    "brands = (\n",
    "    #(brand_id, brand_name)\n",
    "    (100, \"Apple\"),\n",
    "    (200, \"Samsung\"),\n",
    "    (400, \"Google\"),\n",
    "    (500, \"Sony\"),  # no matching product\n",
    ")\n",
    " \n",
    "df_product = ss.createDataFrame(data=products, schema=(\"product_id\", \"product_name\", \"brand_id\"))\n",
    "df_brand = ss.createDataFrame(data=brands, schema=(\"brand_id\", \"brand_name\"))\n",
    "\n",
    "df_product.show(), df_brand.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WRITE DF into DB table\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Writes to `default` DB in the metastore_db --> (Writes to C:/spark/brand_test/ (.parquet files))\n",
    "\"\"\"\n",
    "df_brand.write.mode(\"overwrite\").saveAsTable(\"brand_test\")\n",
    "\n",
    "\"\"\"\n",
    "Writes to the specified database --> (Writes to C:/spark/product_db/brand/ (.parquet files))\n",
    "Creates table in Hive's metastore_db\n",
    "\"\"\"\n",
    "df_brand.write.mode(\"overwrite\").saveAsTable(\"product_db.brand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|brand_id|brand_name|\n",
      "+--------+----------+\n",
      "|     200|   Samsung|\n",
      "|     400|    Google|\n",
      "|     100|     Apple|\n",
      "|     500|      Sony|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ss.sql(\"SELECT * FROM product_db.brand\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method mode in module pyspark.sql.readwriter:\n",
      "\n",
      "mode(saveMode) method of pyspark.sql.readwriter.DataFrameWriter instance\n",
      "    Specifies the behavior when data or table already exists.\n",
      "    \n",
      "    Options include:\n",
      "    \n",
      "    * `append`: Append contents of this :class:`DataFrame` to existing data.\n",
      "    * `overwrite`: Overwrite existing data.\n",
      "    * `error` or `errorifexists`: Throw an exception if data already exists.\n",
      "    * `ignore`: Silently ignore this operation if data already exists.\n",
      "    \n",
      "    >>> df.write.mode('append').parquet(os.path.join(tempfile.mkdtemp(), 'data'))\n",
      "    \n",
      "    .. versionadded:: 1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df_brand.write.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "INNER JOIN\n",
    "df_product (left side of the join) JOIN df_brand (right side of the join)\n",
    "\"\"\"\n",
    "\n",
    "df_product.join(df_brand, df_product[\"brand_id\"] ==  df_brand[\"brand_id\"], how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Same as above.\n",
    "Common join column ca be specified once.\n",
    "\"\"\"\n",
    "\n",
    "df_product.join(df_brand, on=\"brand_id\", how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OUTER JOIN / FULL OUTER JOIN\n",
    "Records from both the left + right DFs (whether matches or not)\n",
    "\"\"\"\n",
    "\n",
    "df_product.join(df_brand, on=\"brand_id\", how=\"outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LEFT / LEFT OUTER JOIN\n",
    "All records from left DF.\n",
    "Unmatched right DF entries appear as null.\n",
    "\"\"\"\n",
    "\n",
    "df_product.join(df_brand, on=\"brand_id\", how=\"left\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LEFT / LEFT OUTER JOIN\n",
    "All records from left DF.\n",
    "Unmatched right DF entries appear as null.\n",
    "\"\"\"\n",
    "\n",
    "df_product.join(df_brand, on=\"brand_id\", how=\"leftouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RIGHT / RIGHT OUTER JOIN\n",
    "All records from right DF.\n",
    "Unmatched left DF entries appear as null.\n",
    "\"\"\"\n",
    "\n",
    "df_product.join(df_brand, on=\"brand_id\", how=\"rightouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LEFT-SEMI JOIN\n",
    "LEFT join with only left-columns retained.\n",
    "\"\"\"\n",
    "\n",
    "print(\"-- join(on) --\")\n",
    "df_product.join(df_brand, on=\"brand_id\", how=\"leftsemi\").show()\n",
    "\n",
    "print(\"-- join(==) --\")\n",
    "df_product.join(df_brand, df_product[\"brand_id\"] ==  df_brand[\"brand_id\"], \"leftsemi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LEFT-ANTI JOIN\n",
    "Exact Opposite of LEFT-SEMI.\n",
    "LEFT join returns left df records that don't have a right-df match!\n",
    "\"\"\"\n",
    "\n",
    "df_product.join(df_brand, on=\"brand_id\", how=\"leftanti\").show()\n",
    "df_product.join(df_brand, df_product[\"brand_id\"] ==  df_brand[\"brand_id\"], \"leftanti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CROSS JOIN\n",
    "Exact Opposite of LEFT-SEMI.\n",
    "LEFT join returns left df records that don't have a right-df match!\n",
    "\"\"\"\n",
    "\n",
    "# df_product.join(df_brand, on=\"brand_id\", how=\"cross\").show()\n",
    "# df_product.join(df_brand, df_product[\"brand_id\"] ==  df_brand[\"brand_id\"], \"cross\").show()\n",
    "df_product.crossJoin(df_brand).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df_product.join)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
