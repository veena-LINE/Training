{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = (\n",
    "    SparkSession.builder.master(\"local\")\n",
    "    .appName(\"sparkSTREAM:basicWC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SETUP: Simple spark streaming\n",
    "\n",
    "ensure `nc -lk 9999` is running\n",
    "\"\"\"\n",
    "\n",
    "df_lines = (\n",
    "    ss.readStream\n",
    "    .format(\"socket\")\n",
    "    .option(\"host\", \"192.168.93.128\")\n",
    "    .option(\"port\", 9999)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    ".show()/print won't work as it's streaming data (not batch data)\n",
    ".printSchema() works\n",
    "\"\"\"\n",
    "\n",
    "df_lines.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split lines into words.\n",
    "Convert words into individual spark records using explode (after splitting on the delimiter \" \")\n",
    ".explode() will convert invidual words into separate spark records\n",
    "\"\"\"\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "df_words = df_lines.select(f.explode(f.split(df_lines.value, \" \")).alias(\"word\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_count = df_words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PRINT schema on console.\n",
    "\n",
    "ensure you don't have an open telnet on the same port you're listening to from here.\n",
    "read data sent from nc command  (linux terminal) and check the output on Jupyter's console\n",
    "\"\"\"\n",
    "\n",
    "echoOnConsole = (\n",
    "    df_word_count\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")  # options: append/complete\n",
    "    .format(\"console\")\n",
    "    .start()  # Starts the query, and spark will subscribe to stream data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"CHECK JUPYTER CONSOLE\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FINALLY: Await termination (before exiting this notebook)\n",
    "\"\"\"\n",
    "\n",
    "echoOnConsole.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
