{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [databricks](https://community.cloud.databricks.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DBFS - Databricks File System\n",
    "Abstraction over HDFS, S3, Azure DataBlobs\n",
    "\n",
    "Create a mount over S3 bucket, then access file via dbfs://mnt/bucketname\n",
    "Accessing dbfs://mnt/bucketname will link to the S3 bucket\n",
    "\n",
    "Write results back to S3 locations as CSV/Parquet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CAN BE MOVED TO A SEPARATE FILE (mount-s3.ipynb)\n",
    "\"\"\"\n",
    "\n",
    "access_key = \"YOUR_ACCESS_KEY\"\n",
    "secret_key = \"YOUR_SECRET_KEY\"\n",
    "bucket_name = \"bond-s3-forspark\"  # AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dbutils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Help on DBUtils in module dbutils object:\n",
    "\n",
    "class DBUtils(builtins.object)\n",
    " |  DBUtils(py_shell, entry_point)\n",
    " |  \n",
    " |  This class provides dbutils functionality for python notebooks, just like dbutils_v1.scala does\n",
    " |  it for Scala. For each of the calls here, we do two things: check whether the passed types are\n",
    " |  correct, and if so make a corresponding call to FSUtils object in Scala. For ls and mounts we do\n",
    " |  one extra thing - instead of returning result directly, we create a PythonSchemaSeq from it\n",
    " |  first. This is done to enable further operations with the result (e.g. call display function\n",
    " |  on it, or perform list operations on it)\n",
    " |  \n",
    " |  Methods defined here:\n",
    " |  \n",
    " |  __call__(self)\n",
    " |      Call self as a function.\n",
    " |  \n",
    " |  __getattr__(self, item)\n",
    " |  \n",
    " |  __getstate__(self)\n",
    " |  \n",
    " |  __init__(self, py_shell, entry_point)\n",
    " |      :param py_shell: the PythonShell object\n",
    " |      :return:\n",
    " |  \n",
    " |  __repr__(self)\n",
    " |      Return repr(self).\n",
    " |  \n",
    " |  help(self, method_name='')\n",
    " |  \n",
    " |  ----------------------------------------------------------------------\n",
    " |  Data descriptors defined here:\n",
    " |  \n",
    " |  __dict__\n",
    " |      dictionary for instance variables (if defined)\n",
    " |  \n",
    " |  __weakref__\n",
    " |      list of weak references to the object (if defined)\n",
    " |  \n",
    " |  ----------------------------------------------------------------------\n",
    " |  Data and other attributes defined here:\n",
    " |  \n",
    " |  CredentialsHandler = <class 'dbutils.DBUtils.CredentialsHandler'>\n",
    " |  \n",
    " |  \n",
    " |  FSHandler = <class 'dbutils.DBUtils.FSHandler'>\n",
    " |  \n",
    " |  \n",
    " |  LibraryHandler = <class 'dbutils.DBUtils.LibraryHandler'>\n",
    " |  \n",
    " |  \n",
    " |  NotebookHandler = <class 'dbutils.DBUtils.NotebookHandler'>\n",
    " |  \n",
    " |  \n",
    " |  PreviewHandler = <class 'dbutils.DBUtils.PreviewHandler'>\n",
    " |      NoOp Preview Handler which is necessary at this moment, as we want Secret module to be under\n",
    " |      preview module. i.e. dbutils.preview.secret\n",
    " |      \n",
    " |      TODO(kevin) After secret module moves out of preview phase, remove this Hanlder and make\n",
    " |                  other corresponding changes to directly call secret module.\n",
    " |  \n",
    " |  SecretsHandler = <class 'dbutils.DBUtils.SecretsHandler'>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CAN BE MOVED TO A SEPARATE FILE (mount-s3.ipynb)\n",
    "\"\"\"\n",
    "\n",
    "encoded_secret_key = secret_key.replace(\"/\", \"%2F\")\n",
    "aws_bucket_name = bucket_name\n",
    "mount_name = bucket_name\n",
    "\n",
    "# if yours is terminated, you need to mount it again.. by running this code..\n",
    "# create a shortcut/mount point /mnt/<<name>> but this points to S3 storages, DBFS\n",
    "# hence s3 files can be accessible either usiing /mnt/bucketname or dbfs://mnt/bucketname\n",
    "dbutils.fs.mount(\"s3a://%s:%s@%s\" % (access_key, encoded_secret_key, aws_bucket_name), \"/mnt/%s\" % mount_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/mnt/%s\" % mount_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "dbfs:/mnt/bond-s3-forspark/movielens/\n",
    "movielens/\n",
    "0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Same as above \"\n",
    "display(dbutils.fs.ls(\"dbfs:///mnt/%s\" % mount_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"dbfs:///mnt/%s/movielens\" % mount_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, LongType, StringType, IntegerType, DoubleType\n",
    "\n",
    "movieSchema = (\n",
    "    StructType()\n",
    "    .add(\"movieId\", IntegerType(), True)\n",
    "    .add(\"title\", StringType(), True)\n",
    "    .add(\"genres\", StringType(), True)\n",
    ")\n",
    "\n",
    "ratingSchema = (\n",
    "    StructType()\n",
    "    .add(\"userId\", IntegerType(), True)\n",
    "    .add(\"movieId\", IntegerType(), True)\n",
    "    .add(\"rating\", DoubleType(), True)\n",
    "    .add(\"timestamp\", StringType(), True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviePath = \"dbfs:///mnt/%s/movielens/movies.csv\" % mount_name\n",
    "ratingPath = \"dbfs:///mnt/%s/movielens/ratings.csv\" % mount_name\n",
    "\n",
    "movieDf = spark.read.format(\"csv\")\\\n",
    "          .option(\"header\", True)\\\n",
    "          .schema(movieSchema)\\\n",
    "          .load(moviePath)\n",
    "\n",
    "ratingDf = spark.read.format(\"csv\")\\\n",
    "          .option(\"header\", True)\\\n",
    "          .schema(ratingSchema)\\\n",
    "          .load(ratingPath)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf.show(2)\n",
    "ratingDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc, avg, count\n",
    "\n",
    "# count, groupBy\n",
    "# a movie, rated by more users, dones't count avg rating\n",
    "# filter, ensure that total_ratings >= 100 users\n",
    "mostPopularDf = ratingDf\\\n",
    "                .groupBy(\"movieId\")\\\n",
    "                .agg(count(\"userId\").alias(\"total_ratings\"), \n",
    "                     avg(\"rating\").alias(\"avg_rating\") )\\\n",
    "                .filter( (col(\"total_ratings\") >= 100) &\n",
    "                         (col(\"avg_rating\") >= 3))\\\n",
    "                .sort(desc(\"total_ratings\"))\n",
    "                \n",
    "mostPopularDf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join mostPopularmovie with movieDf, to get the title of the movie\n",
    "mostPopularMoviesDf = mostPopularDf\\\n",
    "                      .join(movieDf, \n",
    "                            movieDf.movieId == mostPopularDf.movieId)\\\n",
    "                      .select(mostPopularDf.movieId, \"title\", \"total_ratings\", \"avg_rating\")\n",
    "mostPopularMoviesDf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedDf = mostPopularMoviesDf.coalesce(1)\n",
    "cachedDf.cache() # df is cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_movies_path = \"dbfs:///mnt/%s/movielens-results/csv/popular-movies.csv\" % mount_name\n",
    "cachedDf.write.mode('overwrite')\\\n",
    "    .csv(popular_movies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_movies_path = \"dbfs:///mnt/%s/movielens-results/json/popular-movies.json\" % mount_name\n",
    "cachedDf.write.mode('overwrite')\\\n",
    "        .json(popular_movies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_movies_path = \"dbfs:///mnt/%s/movielens-results/parquet/popular-movies.parquet\" % mount_name\n",
    "cachedDf.write.mode('overwrite')\\\n",
    "        .parquet(popular_movies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working, may be due to writer format not available..\n",
    "\"\"\"\n",
    "popular_movies_path = \"dbfs:///mnt/%s/movielens-results/xml/popular-movies.xml\" % mount_name\n",
    "cachedDf.write.mode('overwrite')\\\n",
    "              .format(\"com.databricks.spark.xml\")\\\n",
    "              .option(\"rootTag\", \"movies\")\\\n",
    "              .option(\"rowTag\", \"movie\")\\\n",
    "              .save(popular_movies_path)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
