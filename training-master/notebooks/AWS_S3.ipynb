{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install boto3\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws credentials are taken from ~/.aws/credentials file and aws location is taken from ~./aws/config\n",
    "# Looking at user Home directory C:\\users\\name, linux, cd ~\n",
    "s3 = boto3.resource(\"s3\")\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder suffix / mandatory , after running this, go to aws bucket check the folder present\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.put_object(Bucket=\"ctsspark01\", Key=\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to list all objects in S3 bucket, and their properties\n",
    "\n",
    "all_objects = s3.list_objects(Bucket=\"ctsspark01\")\n",
    "\n",
    "for obj in all_objects[\"Contents\"]:\n",
    "    print(obj)\n",
    "    print(obj[\"Key\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download s3 content and save into c:, after running this code, \n",
    "# check your c:tags-copy.csv present\n",
    "\n",
    "s3.download_file(\"ctsspark01\",   \"movielens/tags.csv\" , \"c:/tags-copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the file into s3 location into a folder /test\n",
    "\n",
    "s3.upload_file(\"c:/tags-copy.csv\", \"ctsspark01\", \"test/tags-copy.csv\")\n",
    "# now check s3, test folder whether tags-copy present or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file content and print the content..\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "obj = s3_resource.Object(\"ctsspark01\", \"test/tags-copy.csv\", )\n",
    "content = obj.get()['Body'].read().decode('utf-8')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'PPQH9M5TWXYZKG45',\n",
       "  'HostId': 'VEh639yrC5Fw8JFWweMOQH1qtAQeQawQEhxJpqyx7NIn2z+wmkBdY7m11DkLlG0KcD83BrSKX0U=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'VEh639yrC5Fw8JFWweMOQH1qtAQeQawQEhxJpqyx7NIn2z+wmkBdY7m11DkLlG0KcD83BrSKX0U=',\n",
       "   'x-amz-request-id': 'PPQH9M5TWXYZKG45',\n",
       "   'date': 'Mon, 24 May 2021 15:10:47 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete object  in s3\n",
    "\n",
    "s3.delete_object(Bucket=\"ctsspark01\", Key=\"test/tags-copy.csv\")\n",
    "\n",
    "# check s3 test folder, the file no more available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a folder  in s3, ensure there is / at end\n",
    "\n",
    "s3.delete_object(Bucket=\"ctsspark01\", Key=\"test/\")\n",
    "\n",
    "# check the bucket in s3, see test folder no more.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
