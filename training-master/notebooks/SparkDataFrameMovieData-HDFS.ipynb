{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "config = SparkConf()\n",
    "config.setMaster(\"spark://192.168.11.71:7077\").setAppName(\"SparkDataFrameHdfs\")\n",
    "#config.setMaster(\"local[2]\").setAppName(\"SparkDataFrameHdfs\")\n",
    "config.set(\"spark.executor.memory\", \"4g\")\n",
    "config.set(\"spark.executor.cores\", 4)\n",
    "config.set(\"spark.cores.max\", 4)\n",
    "config.set(\"spark.driver.memory\", \"4g\")\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config(conf=config).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, LongType,StringType, IntegerType, DoubleType\n",
    "\n",
    "movieSchema = StructType()\\\n",
    "         .add(\"movieId\", IntegerType(), True)\\\n",
    "         .add(\"title\", StringType(), True)\\\n",
    "         .add(\"genres\", StringType(), True)\\\n",
    "\n",
    "\n",
    "ratingSchema = StructType()\\\n",
    "         .add(\"userId\", IntegerType(), True)\\\n",
    "         .add(\"movieId\", IntegerType(), True)\\\n",
    "         .add(\"rating\", DoubleType(), True)\\\n",
    "         .add(\"timestamp\", StringType(), True)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf = spark.read.format(\"csv\")\\\n",
    "          .option(\"header\", True)\\\n",
    "          .schema(movieSchema)\\\n",
    "          .load(\"hdfs://192.168.93.128:9000/ml-latest-small/movies.csv\")\n",
    "\n",
    "ratingDf = spark.read.format(\"csv\")\\\n",
    "          .option(\"header\", True)\\\n",
    "          .schema(ratingSchema)\\\n",
    "          .load(\"hdfs://192.168.93.128:9000/ml-latest-small/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf.show(2)\n",
    "ratingDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of all 4 columns, we pick below 2 columns\n",
    "df2 = ratingDf.select(\"movieId\", \"rating\")\n",
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count\n",
    "\n",
    "print(\"Count \", ratingDf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all columns\n",
    "print(\"Columns\", ratingDf.columns)\n",
    "# schema\n",
    "print(ratingDf.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and return new dataframe with 2 columns movieId, rating\n",
    "df3 = ratingDf.select(\"movieId\", \"rating\")\n",
    "df3.printSchema()\n",
    "df3.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDf.show(1)\n",
    "# add new columns/drive new columns from existing data\n",
    "df3 = ratingDf.withColumn(\"rating_adjusted\", ratingDf.rating + .2  )\n",
    "df3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDf.show(1)\n",
    "# rename the column in the df\n",
    "# existing col, new column\n",
    "df2 = ratingDf.withColumnRenamed(\"rating\", \"ratings\")\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variance\n",
    "# select all columns\n",
    "df2 = ratingDf.select(\"*\")\n",
    "df2.show(1)\n",
    "df2 = ratingDf.select(\"movieId\", \"rating\")\n",
    "df2.show(1)\n",
    "# use .alias to give a name\n",
    "df2 = ratingDf.select(ratingDf.userId, \n",
    "                     (ratingDf.rating + 0.2).alias(\"rating_adjusted\") )\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter, apply predicates/conditions\n",
    "# filter, where functions. where is an alias of filter, both are same\n",
    "df2 = ratingDf.filter(ratingDf.rating > 4)\n",
    "df2.show(3)\n",
    "\n",
    "df2 = ratingDf.where(ratingDf.rating > 4)\n",
    "df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple conditions\n",
    "df2 = ratingDf.filter( (ratingDf.rating >=3) & (ratingDf.rating <=4))\n",
    "df2.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df2 = ratingDf.filter( (col(\"rating\") >=3) & (col(\"rating\") <=4))\n",
    "df2.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, asc, desc\n",
    "# sort data by ascending order/ default\n",
    "df2 = ratingDf.sort(\"rating\")\n",
    "df2.show(5)\n",
    "# sort data by ascending by explitly\n",
    "df2 = ratingDf.sort(asc(\"rating\"))\n",
    "df2.show(5)\n",
    "# sort data by descending order\n",
    "df2 = ratingDf.sort(desc(\"rating\"))\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation count\n",
    "from pyspark.sql.functions import col, desc, avg, count\n",
    "# count, groupBy\n",
    "# a movie, rated by more users, dones't count avg rating\n",
    "# filter, ensure that total_ratings >= 100 users\n",
    "mostPopularDf = ratingDf\\\n",
    "                .groupBy(\"movieId\")\\\n",
    "                .agg(count(\"userId\"))\\\n",
    "                .withColumnRenamed(\"count(userId)\", \"total_ratings\")\\\n",
    "                .filter(col(\"total_ratings\") >= 100)\\\n",
    "                .sort(desc(\"total_ratings\"))\\\n",
    "                \n",
    "\n",
    "mostPopularDf.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join mostPopularmovie with movieDf, to get the title of the movie\n",
    "mostPopularMoviesDf = mostPopularDf\\\n",
    "                      .join(movieDf, \n",
    "                            movieDf.movieId == mostPopularDf.movieId)\\\n",
    "                      .select(mostPopularDf.movieId, \"title\", \"total_ratings\")\n",
    "\n",
    "\n",
    "\n",
    "mostPopularMoviesDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform two aggregates, count, avg, \n",
    "\n",
    "# aggregation of count of number of votes, +\n",
    "# aggregation of avg voting\n",
    "from pyspark.sql.functions import col, desc, avg, count\n",
    "# count, groupBy\n",
    "# a movie, rated by more users, dones't count avg rating\n",
    "# filter, ensure that total_ratings >= 100 users\n",
    "mostPopularDf = ratingDf\\\n",
    "                .groupBy(\"movieId\")\\\n",
    "                .agg(count(\"userId\").alias(\"total_ratings\"), \n",
    "                     avg(\"rating\").alias(\"avg_rating\") )\\\n",
    "                .filter( (col(\"total_ratings\") >= 100) &\n",
    "                         (col(\"avg_rating\") >= 3))\\\n",
    "                .sort(desc(\"total_ratings\"))\n",
    "                \n",
    "mostPopularDf.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join mostPopularmovie with movieDf, to get the title of the movie\n",
    "mostPopularMoviesDf = mostPopularDf\\\n",
    "                      .join(movieDf, \n",
    "                            movieDf.movieId == mostPopularDf.movieId)\\\n",
    "                      .select(mostPopularDf.movieId, \"title\", \"total_ratings\", \"avg_rating\")\n",
    "\n",
    "\n",
    "\n",
    "mostPopularMoviesDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will write the result to file system local\n",
    "# create a folder named \"output\" in c:\n",
    "# open command prompt\n",
    "# run below command to assign permission \n",
    "#   winutils.exe chmod -R 777 c:\\output\n",
    "\n",
    "mostPopularMoviesDf.write.mode('overwrite')\\\n",
    "                         .csv(\"hdfs://192.168.93.128:9000/output/top-moives\")\n",
    "\n",
    "#mostPopularMoviesDf.toPandas()\\\n",
    "#                    .to_csv(\"c:/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repartition to adjust partitions\n",
    "# use it only to increase the number of partition, not to reduce it.\n",
    "# reparition shall do shuffle always\n",
    "# BAD approach, we use reparition for reducing number of parition, bad , due to shuffling performance\n",
    "mostPopularMoviesDf.repartition(1).write.mode('overwrite')\\\n",
    "                         .csv(\"hdfs://192.168.93.128:9000/output/top-movies-one-file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coalesce helps to reparitions tooo\n",
    "# should be used to reduce the partitions, should not be used to increase the parititions\n",
    "# coalesce shall possibly reduce the shuffling, but cannot stop shuffling \n",
    "mostPopularMoviesDf.coalesce(1).write.mode('overwrite')\\\n",
    "                         .csv(\"hdfs://192.168.93.128:9000/output/top-movies-coalesce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topMovieSchema = StructType()\\\n",
    "         .add(\"movieId\", IntegerType(), True)\\\n",
    "         .add(\"title\", StringType(), True)\\\n",
    "         .add(\"total_ratings\", DoubleType(), True)\\\n",
    "         .add(\"avg_rating\", DoubleType(), True)\\\n",
    "\n",
    "# Spark can read folder/directory, understanding the partitions files, ordering\n",
    "\n",
    "topMovies = spark.read.format(\"csv\")\\\n",
    "          .option(\"header\", False)\\\n",
    "          .schema(topMovieSchema)\\\n",
    "          .load(\"hdfs://192.168.93.128:9000/output/top-moives\")\n",
    "\n",
    "topMovies.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
