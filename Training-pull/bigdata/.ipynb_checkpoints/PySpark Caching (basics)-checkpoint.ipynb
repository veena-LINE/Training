{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[1]\", \"CACHE\")\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform1(n):\n",
    "    print(f\"Transform1 {n}\")\n",
    "    return n\n",
    "\n",
    "rdd_transform1 = rdd.map(lambda x: transform1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2(n):\n",
    "    print(f\"Transform2 {n}\")\n",
    "    return n\n",
    "\n",
    "rdd_transform2 = rdd_transform1.map(lambda x: transform2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_result1 = rdd_transform2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_result2 = rdd_transform2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_result3 = rdd_transform2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at collect at <ipython-input-6-7aac3a24c8a2>:1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Every call to rdd_transform2 results in an expensive call to it's transformations.\n",
    "Solution: Caching with .persist()\n",
    "\"\"\"\n",
    "rdd_transform2.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_transform2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_transform2.is_cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Uncaching: 2 ways:\n",
    "1. Upon Driver exiting naturally.\n",
    "2. rdd.unpersist()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_transform2.unpersist()\n",
    "rdd_transform2.is_cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Caching Storage Levels\n",
    "1. DISK ONLY - slower I/O\n",
    "2. MEMORY ONLY - faster I/O\n",
    "3. MEMORY and DISK - balances the above two (MEMORY first, spills-ver to DISK)\n",
    "\n",
    "\n",
    "rdd.cache(StorageLevel.DISK_ONLY)\n",
    "rdd.persist() internally calls cache function.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".cache() calls .persist() internally, with MEMORY_ONLY.\n",
    "\n",
    "Call to .cache() is simple., you can't pass StorageLevel options.\n",
    "Want to control where data's chached? .persist(StorageLevel.<option>)\n",
    "\"\"\"\n",
    "rdd_transform2.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at collect at <ipython-input-9-f26e13ae07bc>:1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "rdd_transform2.persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "\"\"\"\n",
    "To alter StorageLevel, .unpersist() first.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StorageLevel in module pyspark.storagelevel:\n",
      "\n",
      "class StorageLevel(builtins.object)\n",
      " |  StorageLevel(useDisk, useMemory, useOffHeap, deserialized, replication=1)\n",
      " |  \n",
      " |  Flags for controlling the storage of an RDD. Each StorageLevel records whether to use memory,\n",
      " |  whether to drop the RDD to disk if it falls out of memory, whether to keep the data in memory\n",
      " |  in a JAVA-specific serialized format, and whether to replicate the RDD partitions on multiple\n",
      " |  nodes. Also contains static constants for some commonly used storage levels, MEMORY_ONLY.\n",
      " |  Since the data is always serialized on the Python side, all the constants use the serialized\n",
      " |  formats.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, useDisk, useMemory, useOffHeap, deserialized, replication=1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  DISK_ONLY = StorageLevel(True, False, False, False, 1)\n",
      " |  \n",
      " |  DISK_ONLY_2 = StorageLevel(True, False, False, False, 2)\n",
      " |  \n",
      " |  MEMORY_AND_DISK = StorageLevel(True, True, False, False, 1)\n",
      " |  \n",
      " |  MEMORY_AND_DISK_2 = StorageLevel(True, True, False, False, 2)\n",
      " |  \n",
      " |  MEMORY_AND_DISK_SER = StorageLevel(True, True, False, False, 1)\n",
      " |  \n",
      " |  MEMORY_AND_DISK_SER_2 = StorageLevel(True, True, False, False, 2)\n",
      " |  \n",
      " |  MEMORY_ONLY = StorageLevel(False, True, False, False, 1)\n",
      " |  \n",
      " |  MEMORY_ONLY_2 = StorageLevel(False, True, False, False, 2)\n",
      " |  \n",
      " |  MEMORY_ONLY_SER = StorageLevel(False, True, False, False, 1)\n",
      " |  \n",
      " |  MEMORY_ONLY_SER_2 = StorageLevel(False, True, False, False, 2)\n",
      " |  \n",
      " |  OFF_HEAP = StorageLevel(True, True, True, False, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StorageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
