{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `$pip install findspark`\n",
    "<span style=\"color:red\">Note: This is not to be done on production!</span>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This starts the Spark Driver and the Executor\n",
    "# Check Jupyter console for the Spark session port (4040/1/?)\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(\"local\", \"Read-Write-HDFS\")\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext\n",
    "\n",
    "# sc = SparkContext(\"local\", \"Read-Write-HDFS\")\n",
    "\n",
    "# rdd_data = sc.textFile(\"hdfs://192.168.93.128:9000/input/README.md\")\n",
    "# print(type(rdd_data))\n",
    "\n",
    "# rdd_data_title = rdd_data.map(lambda line: line.title())\n",
    "\n",
    "# rdd_data_title.saveAsTextFile(\"hdfs://192.168.93.128:9000/output/README2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd_data = sc.textFile(\"hdfs://192.168.93.128:9000/output/README2\")\n",
    "\n",
    "# rdd_data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: Lazy\n",
    "rdd_data = sc.textFile(\"hdfs://192.168.93.128:9000/input/all_us_states.csv\")\n",
    "\n",
    "# Check Spark UI Monitoring (nothing happens as this is lazy loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMATION, Lazy\n",
    "rdd_upper = rdd_data.map(lambda line: line.upper())\n",
    "\n",
    "# Check Spark UI Monitoring (nothing happens as this is lazy loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABBR,NAME',\n",
       " 'AL,ALABAMA',\n",
       " 'AK,ALASKA',\n",
       " 'AZ,ARIZONA',\n",
       " 'AR,ARKANSAS',\n",
       " 'CA,CALIFORNIA',\n",
       " 'CO,COLORADO',\n",
       " 'CT,CONNECTICUT',\n",
       " 'DE,DELAWARE',\n",
       " 'DC,DISTRICT OF COLUMBIA']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACTION\n",
    "\n",
    "rdd_upper.take(10)\n",
    "\n",
    "# Because this is an ACTION, Spark will convert the RDD into a DAG (with RRDD creation as the parent, the action (.take()) as the child)\n",
    "# Every ACTION triggers a JOB\n",
    "# A JOB contains STAGEs of TASKs inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data_header = rdd_data.first()\n",
    "rdd_data_states = rdd_data.filter(lambda line: line != rdd_data_header)\n",
    "rdd_data_states.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rdd_data_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Tuple RDD is a.k.a Keyed RDD\n",
    "rdd_states_tuple = rdd_data_states.map(lambda line: line.split(\",\")).map(lambda state: (state[0], state[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AL', 'Alabama'),\n",
       " ('AK', 'Alaska'),\n",
       " ('AZ', 'Arizona'),\n",
       " ('AR', 'Arkansas'),\n",
       " ('CA', 'California'),\n",
       " ('CO', 'Colorado'),\n",
       " ('CT', 'Connecticut'),\n",
       " ('DE', 'Delaware'),\n",
       " ('DC', 'District of Columbia'),\n",
       " ('FL', 'Florida'),\n",
       " ('GA', 'Georgia'),\n",
       " ('HI', 'Hawaii'),\n",
       " ('ID', 'Idaho'),\n",
       " ('IL', 'Illinois'),\n",
       " ('IN', 'Indiana'),\n",
       " ('IA', 'Iowa'),\n",
       " ('KS', 'Kansas'),\n",
       " ('KY', 'Kentucky'),\n",
       " ('LA', 'Louisiana'),\n",
       " ('ME', 'Maine'),\n",
       " ('MD', 'Maryland'),\n",
       " ('MA', 'Massachusetts'),\n",
       " ('MI', 'Michigan'),\n",
       " ('MN', 'Minnesota'),\n",
       " ('MS', 'Mississippi'),\n",
       " ('MO', 'Missouri'),\n",
       " ('MT', 'Montana'),\n",
       " ('NE', 'Nebraska'),\n",
       " ('NV', 'Nevada'),\n",
       " ('NH', 'New Hampshire'),\n",
       " ('NJ', 'New Jersey'),\n",
       " ('NM', 'New Mexico'),\n",
       " ('NY', 'New York'),\n",
       " ('NC', 'North Carolina'),\n",
       " ('ND', 'North Dakota'),\n",
       " ('OH', 'Ohio'),\n",
       " ('OK', 'Oklahoma'),\n",
       " ('OR', 'Oregon'),\n",
       " ('PA', 'Pennsylvania'),\n",
       " ('RI', 'Rhode Island'),\n",
       " ('SC', 'South Carolina'),\n",
       " ('SD', 'South Dakota'),\n",
       " ('TN', 'Tennessee'),\n",
       " ('TX', 'Texas'),\n",
       " ('UT', 'Utah'),\n",
       " ('VT', 'Vermont'),\n",
       " ('VA', 'Virginia'),\n",
       " ('WA', 'Washington'),\n",
       " ('WV', 'West Virginia'),\n",
       " ('WI', 'Wisconsin'),\n",
       " ('WY', 'Wyoming')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_states_tuple.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default sort order = ASCENDING\n",
    "rdd_states_sorted = rdd_states_tuple.sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AK', 'Alaska'),\n",
       " ('AL', 'Alabama'),\n",
       " ('AR', 'Arkansas'),\n",
       " ('AZ', 'Arizona'),\n",
       " ('CA', 'California'),\n",
       " ('CO', 'Colorado'),\n",
       " ('CT', 'Connecticut'),\n",
       " ('DC', 'District of Columbia'),\n",
       " ('DE', 'Delaware'),\n",
       " ('FL', 'Florida'),\n",
       " ('GA', 'Georgia'),\n",
       " ('HI', 'Hawaii'),\n",
       " ('IA', 'Iowa'),\n",
       " ('ID', 'Idaho'),\n",
       " ('IL', 'Illinois'),\n",
       " ('IN', 'Indiana'),\n",
       " ('KS', 'Kansas'),\n",
       " ('KY', 'Kentucky'),\n",
       " ('LA', 'Louisiana'),\n",
       " ('MA', 'Massachusetts'),\n",
       " ('MD', 'Maryland'),\n",
       " ('ME', 'Maine'),\n",
       " ('MI', 'Michigan'),\n",
       " ('MN', 'Minnesota'),\n",
       " ('MO', 'Missouri'),\n",
       " ('MS', 'Mississippi'),\n",
       " ('MT', 'Montana'),\n",
       " ('NC', 'North Carolina'),\n",
       " ('ND', 'North Dakota'),\n",
       " ('NE', 'Nebraska'),\n",
       " ('NH', 'New Hampshire'),\n",
       " ('NJ', 'New Jersey'),\n",
       " ('NM', 'New Mexico'),\n",
       " ('NV', 'Nevada'),\n",
       " ('NY', 'New York'),\n",
       " ('OH', 'Ohio'),\n",
       " ('OK', 'Oklahoma'),\n",
       " ('OR', 'Oregon'),\n",
       " ('PA', 'Pennsylvania'),\n",
       " ('RI', 'Rhode Island'),\n",
       " ('SC', 'South Carolina'),\n",
       " ('SD', 'South Dakota'),\n",
       " ('TN', 'Tennessee'),\n",
       " ('TX', 'Texas'),\n",
       " ('UT', 'Utah'),\n",
       " ('VA', 'Virginia'),\n",
       " ('VT', 'Vermont'),\n",
       " ('WA', 'Washington'),\n",
       " ('WI', 'Wisconsin'),\n",
       " ('WV', 'West Virginia'),\n",
       " ('WY', 'Wyoming')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_states_sorted.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WY', 'Wyoming'),\n",
       " ('WV', 'West Virginia'),\n",
       " ('WI', 'Wisconsin'),\n",
       " ('WA', 'Washington')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_states_tuple.sortByKey(False).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_states_tuple.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing results (in tuple form) into HDFS\n",
    "rdd_states_sorted.saveAsTextFile(\"hdfs://192.168.93.128:9000/output/states_sorted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.textFile(\"hdfs://192.168.93.128:9000/output/states_sorted\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_count = rdd_states_tuple.countByKey()\n",
    "print(states_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd_states_count = rdd_states_tuple.map(lambda state: (state[0], 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "print(rdd_data_states.map(lambda line: (line.split(\",\")[0],)).countByKey())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
